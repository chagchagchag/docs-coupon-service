{"/about":{"title":"About","data":{"":"This is the about page! This page is shown on the navbar."}},"/coding-style/factory-mapper-usage":{"title":"Factory Mapper Usage","data":{"객체생성은-factory-mapper-컴포넌트를-사용#객체생성은 factory, mapper 컴포넌트를 사용":""}},"/coding-style/multi-module-usage":{"title":"Multi Module Usage","data":{"멀티모듈-구성-원칙#멀티모듈 구성 원칙":""}},"/coding-style/simplify-object-dependency":{"title":"Simplify Object Dependency","data":{"객체-간-의존성-단순화-순환참조-방지#객체 간 의존성 단순화 (순환참조 방지)":"엄청나게 어려운 이야기는 아니지만, 실무에서 유지보수를 하는 중에 기능 추가 시에 순환참조가 발생하는 경우가 가끔씩 있었고 이런 경우를 우회하기 위해 별도의 객체를 생성해서 우회했던 경험이 있습니다.이런 경우가 어떤 경우였을까를 생각해보면 보통 Service A 에서 어떤 단위기능들을 조합해서 호출하고 있는데 요구사항에 따라 Service B 를 호출하게 되었습니다. 시간이 흘러서 Service B 에서도 Service A 를 호출해야만 하는 경우가 발생했습니다.이런 경우 순환 참조가 발생합니다.\r\n이런 문제를 풀어낼 수 있는 가장 쉬운 방법은 Service 내에서 다른 Service 를 의존성 주입받지 않도록 하고, 하나의 Service 가 하나의 역할만을 담당하도록 하는 것입니다.조금 두루뭉술하게 설명했는데, 결론은 대리인 역할을 하는 하나의 프록시 역할의 객체를 두어서 어떤 기능을 필요로 할 때 이 프록시 객체를 통해서 호출하도록 하는 것입니다.그리고 같은 계층 내의 각각의 대리인 객체들 각각은 서로를 의존하거나 의존성주입 받지 않고 독립적으로 존재하도록 구성합니다.계층이나 모듈의 기능이나 역할을 명확히 해두어서 그 계층에서의 대리인 역할의 객체는 다른 객체에 의존하지 않도록 계층이나 모듈이 의미와 기능을 명확히 하도록 구성하면 이런 작업들이 쉬워지게 됩니다.이번 프로젝트에서는 애플리케이션의 하위 모듈들 내에서 필요한 대표적인 기능들을 application, dataaccess, domain 계층으로 분류했고 계층별 대리인 객체의 기능을 정해두면서 설계를 했고 이런 기능들은 멀티 모듈로 분리해서 개발작업을 하면서 더 세분화 되었던 것 같습니다.","기본적인-컨셉-및-원칙들#기본적인 컨셉 및 원칙들":"주요 원칙은 아래와 같습니다.\n단위 기능 클래스 안에서 다른 단위기능 클래스를 의존성 주입받지 않는다. 단위기능 클래스는 단위 기능을 하는 데에만 집중한다.\n단위 기능을 접근할 때는 @Service 로 정의한 컴포넌트를 통해 접근한다. @Service 에서는 단위기능을 불러들여서 의존성을 주입받아서 비즈니스 로직을 정의한다.\n하나의 계층에 존재하는 Service A 와 Service B 는 서로를 참조하지 않으며 의존성 주입 역시 받지 않는 서로 독립적인 객체로 정의하는 것을 원칙으로 한다.\n이렇게 중간에서 각각이 독립적인 역할을 하도록 Service 객체를 구성하며 대리인 역할을 하게끔 한다. 이렇게 대리인 역할의 객체에게만 @Service 어노테이션을 붙이기로 하며, -Service 접미사를 붙인다.\n그 외의 단위기능의 경우 Repository 로 정의하거나 @Component 로 정의해서 단위 기능임을 확실하게 표현한다.\ne.g. application 계층에서 dataaccess 계층의 CouponJpaRepository 를 접근하려는 경우\ncoupon-api 모듈 내의 application 계층에서는 단순하게 dataaccess 계층에서 대리인 역할을 하는 객체만 알고 있으면 되고 어떤 함수를 호출하면 되는지만 알면 됩니다.\n따라서 CouponApiApplicationService 에서는 Data에 접근이 필요할 경우 단순하게 CouponDataAccessService 라는 대리인 객체를 의존성 주입 받은 후 CouponDataAccessService 내에 정의해둔 비즈니스 로직을 통해서 접근하도록 하면 됩니다.","eg-issue-로직을-통해-mysql에-쿠폰을-발급하는-기능#e.g. issue() 로직을 통해 MySQL에 쿠폰을 발급하는 기능":"","eg-api-의-request-를-redis-에-enqueue-하는-기능#e.g. API 의 Request 를 Redis 에 enqueue 하는 기능":""}},"/performance-test/locust-setting":{"title":"Locust Setting","data":{"locust-세팅#Locust 세팅":"Locust 에서는 아래와 같이 세팅을 해줍니다. 1100 명의 User 인입을 테스트하는 것이고 1초에 100 명의 유저를 생성해냅니다. Host 는 http://host.docke.internal:8080 로 지정했습니다.\r\n모두 선택했다면 Start Swarming 을 눌러서 실행합니다."}},"/performance-test/grafana-dashboard-setting":{"title":"Grafana Dashboard Setting","data":{"grafana-dashboard-세팅#Grafana Dashboard 세팅":"Tomcat 커넥션이 얼마나 증가하는지를 보기 위한 지표 차트를 세팅합니다.Utilisation 내의 점 세개 버튼 클릭 → More ... → Duplicate 클릭\r\n이동한 페이지에서는 오른쪽의 Builder 버튼 클릭 후 Metric 중에서 tomcat_connections_current_connections 를 선택합니다. 그리고 Run queries 를 클릭합니다.\r\nOptions 버튼 클릭 후 Legend 항목에는 톰캣 커넥션 (current) 를 입력해줍니다. 이어서 오른쪽에서 Panel Options 의 Title 도 아래와 같이 알아볼 수 있는 제목을 지어줍니다.\r\n모두 완료되었으면 우측 상단의 Apply 버튼을 클릭합니다.\r\n대시보드 페이지에서는 변경된 사항을 저장하기 위해 디스켓 모양의 버튼을 클릭해서 현재 대시보드의 상태를 저장합니다."}},"/":{"title":"Introduction","data":{"":"Project Github : https://github.com/chagchagchag/coupon-service\nDocs Github : https://github.com/chagchagchag/docs-coupon-service\n안녕하세요. 이 프로젝트 게시판은 Redis와 Spring Boot 를 이용해서 작업 대기열을 어떻게 처리하는지, 모니터링 도구는 어떻게 구성하는지를 알아갈 수 있는 예제와 여기에 대한 문서자료를 담은 페이지입니다.\n트래픽이 엄청 높은 경우에는 레디스를 사용할 경우 Memory 가 터질 수 있다는 위험요소도 있고 트래픽의 실제 범위를 알 수 없기에 실무에서 적용하기에 완벽하게 적합한 예제는 아닙니다.\r\n트래픽이 굉장히 높은 구조에서는 무한한 트래픽을 수용할 수 있도록 증분 기록이 가능하도록 하는 편이고, 디스크 용량 역시 외부에서 수정이 가능한 구조로 설계해야 하고, 보통은 이런 요구사항들은 실무에서는 카프카와 EDA, 분산 트랜잭션을 통해 이런 부분들을 해결합니다.\r\n카프카 역시 디스크에 메시징 기록들을 증분기록하는 방식이고 내부적으로는 RocksDB라는 Offheap 기반 데이터베이스를 사용하고, 토픽의 모든 내용들이 디스크에 기록이 되기에 이벤트가 모두 기록된다는 장점이 있고 EDA 의 SAGA, Outbox 개념을 통해 분산 트랜잭션을 통해 단일 DB로 요청이 몰릴 경우에 대한 위험을 분산하고 가용성을 늘리며, 트랜잭션을 이벤트 기반으로 처리함으로써 유지보수성을 향상시키는 편입니다.\n다만, 이번 예제는 단순히 레디스를 어떻게 사용하는지, RedisScript 는 무엇인지, 모니터링 도구는 어떻게 구성하고, 테스트 환경은 어떻게 구성하는지, 프로젝트에서는 어떤 코드 작성방식을 선택했는지 등을 설명하기 위해 간단한 문서페이지를 작성했습니다.\n제 입장에서는 취업을 위해 어쩔 수 없이 준비했지만, 혹시라도 들르셨을 지도 모르는 디지털 나그네분들에게 조금이라도 도움이 되기를 바랍니다."}},"/performance-test/testing-note":{"title":"Testing Note","data":{"테스팅-기록#테스팅 기록":"","coupon-데이터-생성#Coupon 데이터 생성":"쿠폰의 발급 가능한 총 개수를 1000 으로 설정했습니다. 1100 명의 사용자가 요청을 하더라도 1000명 까지만 발급이 가능합니다.\nINSERT INTO coupon.coupons(\r\n    title, coupon_assign_type, total_quantity, issued_quantity, discount_amount,\r\n    min_available_amount, issue_start_datetime, issue_end_datetime, created_datetime, updated_datetime\r\n)\r\nVALUES (\r\n           '50% 세일. 과연 누가 주인공이 될 것인가?', 'FIFO', 1000, 0, 50,\r\n           1000, '2024-01-01 00:00:01', '2024-11-11 23:59:59', '2023-12-31 23:00:00', '2023-12-31 23:00:00'\r\n       );\r\n\r\nCOMMIT;","locust#Locust":"먼저 Locust 에서 아래의 세팅을 통해서 아래의 테스트 조건을 걸어주고 테스트를 시작합니다.","데이터-저장-확인#데이터 저장 확인":"coupon_issues 테이블에는 아래와 같이 1000개의 coupon 이 정상적으로 저장되어 있음을 확인 가능합니다.\r\ncoupons 테이블에는 아래와 같이 정상적으로 issued_quantity 가 1000 으로 정상적으로 세팅된 것을 확인 가능합니다.","레디스-확인#레디스 확인":"","데이터-요청-대기열-확인#데이터 요청 대기열 확인":"요청 대기열은 아래와 같이 테스트 초기에는 936 개의 요청을 저장하고 있습니다.\r\n잠시 동안의 순간에 Refresh 버튼을 눌러서 새로 변경된 내용을 조회해보면 아래와 같이 473 개의 요청으로 줄어들어 있습니다.\r\n정상적으로 작업 대기열이 비워지고 있습니다.","데이터-요청-기록-set-확인#데이터 요청 기록 SET 확인":"SortedSet 을 사용할수도 있겠지만, Set과 List 를 조합한 FIFO 구조로 작업 대기열을 구성했는데, List 를 통해 FIFO 를 구현했고, 요청 각각은 Set 을 통해 요청 고유값을 식별합니다. 따라서 Set 의 Size 가 1000 개라면 정상적으로 요청을 모두 받아두었다는 것을 확인 가능합니다.","grafana-확인#Grafana 확인":"coupon-api 의 상태를 그라파나를 통해 확인해봅니다. locust 를 통해 coupon-api 로 유입되어서 톰캣 커넥션 수가 증가하고, 레디스에 접근하는 IO 작업 역시 증가함을 확인 가능합니다.\r\ncoupon-issuer 의 상태입니다."}},"/project-overview/locust-setting":{"title":"Locust Setting","data":{"locust-세팅하기#locust 세팅하기":"locust 는 성능부하를 테스트하기 위한 테스트입니다. docker-compose 등을 통해 스케일링이 가능하고, 기본으로 제공하는 dashboard 도 강력하기에 성능부하를 실험하고, 측정하기에 용이한 도구입니다.","참고#참고":"locust.io\ndocs.locust.io/en/stable","api-정의#API 정의":"테스트할 API 를 정의합니다.\n@RequiredArgsConstructor\r\n@RestController\r\npublic class CouponApiController {\r\n\r\n    private final CouponApplicationService couponApplicationService;\r\n\r\n    @PostMapping(\"/coupon/issue\")\r\n    public CouponIssueResponse issue(@RequestBody CouponIssueRequest request){\r\n        couponApplicationService.issueAsync(request);\r\n        return new CouponIssueResponse(SUCCESS, SUCCESS.getMessageKr());\r\n    }\r\n\r\n}\n위의 코드에서 CouponApplicationService 클래스 내의 issueAsync(request) 메서드는 아무 동작도 하지 않는 비어있는 메서드입니다.","docker-compose#docker-compose":"docker-compose 파일을 아래와 같이 작성해줍니다.\nversion: '3.7'\r\nservices:\r\n  master:\r\n    image: locustio/locust\r\n    ports:\r\n      - \"8089:8089\"\r\n    volumes:\r\n      - ./:/mnt/locust\r\n    command: -f /mnt/locust/locustfile-coupon-request.py --master -H http://host.docker.internal:8080\r\n\r\n  worker:\r\n    image: locustio/locust\r\n    volumes:\r\n      - ./:/mnt/locust\r\n    command: -f /mnt/locust/locustfile-coupon-request.py --worker --master-host master","python-파일-정의#python 파일 정의":"import random\r\nfrom locust import task, FastHttpUser, stats\r\n\r\nstats.PERCENTILES_TO_CHART = [0.95, 0.99]\r\n\r\n\r\nclass CouponRequest(FastHttpUser):\r\n    connection_timeout = 10.0\r\n    network_timeout = 10.0\r\n\r\n    @task\r\n    def issue(self):\r\n        payload = {\r\n            \"userId\": random.randint(1, 10000000),\r\n            \"couponId\": 1\r\n        }\r\n        with self.rest(\"POST\", \"/coupon/issue\", json=payload):\r\n            pass","실행#실행":"아래의 명령어를 통해 실행합니다.\ndocker-compose up -d --scale worker=3","docker-desktop-확인#Docker Desktop 확인":"아래와 같이 worker 3기, master 1의 구성으로 docker 애플리케이션이 구동된 모습을 확인 가능합니다.","locust-애플리케이션-접속#locust 애플리케이션 접속":"","load-설정#load 설정":"Number of users\n몇명의 사용자까지 만들어낼 것인지\n위의 사진에서는 10만명까지의 유입을 만들어내겠다는 의미\nSpawn rate\n1초에 몇명의 사용자를 생성해낼 것인지\n위의 사진에서는 1초에 1000명씩 유저를 생성되어서 유입되게끔 했습니다.\n1초: 1000명, 2초: 2000명, 3초: 3000명, ... 100초 : 100000명\nHost\n요청을 보낼 주소","load-테스트#load 테스트":"로드를 spawning 하고 있는 모습\r\n차트 탭\r\nFailures 탭\r\n요청이 실패한 것의 기록이다.\r\n이번에는 Workers 탭으로 이동한다. 자세히 보면 CPU 사용률이 100% 이상으로 올라가고 있다.\r\nworker 들의 로드를 줄여주기 위해 이번에는 worker 수를 7개로 늘려봅니다.\n$ docker-compose scale worker=7\n각 worker 의 cpu 사용량은 줄어들었습니다."}},"/project-overview/module-structure":{"title":"멀티 모듈 구조","data":{"coupon-core#coupon-core":"DomainEvent\n각종 ErrorCode, Exception\nJPA Entity, Cache Value Object","coupon-dataaccess#coupon-dataaccess":"JPA, Querydsl, Redis, RedisScript, Caffeine 에 대한 처리 코드들을 모아두고 JPA 설정 코드들이 모여 있는 모듈입니다.\n처음에는 coupon-dataaccess 에 데이터 코드를 모아둘까 하다가 귀차니즘 으로 이렇게 하는 것 같다는 생각이 들어서 프로젝트 중반에 coupon-api, coupon-issuer 마다 각각의 데이터 접근코드를 두기로 결정했었습니다.\n막상 개발과 설계를 수정하는 과정을 거치면서 coupon 이라는 서비스 측면에서 data 조회의 버전을 따로 관리하는 모듈을 따로 분리해둔다면 더 나을 것이라는 판단이 들어서 coupon-dataaccess 모듈을 따로 구현하게 되었습니다.","coupon-api#coupon-api":"사용자의 접근 포인트\n사용자의 요청이 잘못 되었는지 유효성 검증 수행\nWrite Back 기반으로 요청들을 쌓아두는 역할을 수행\ne.g.\n쿠폰 1개에 대해 10000 명의 사용자가 접속해서 발급하려 하는 경우\n주요 코드\ncontroller, advice\ncoupon-dataaccess 를 이용해서 Redis Queue 처리 작업을 하고, ErrorCode, Exception 등은 coupon-core 모듈을 이용","coupon-issuer#coupon-issuer":"쿠폰 발급기 (실제 DB에 저장하는 작업을 수행)\nRedis 에 저장된 쿠폰 발급 요청을 꺼내어서 MySQL에 쿠폰 발급 요청 데이터를 실제로 저장하는 작업 수행\n스케쥴링(@Scheduled) 기반의 데이터 저장 처리\nMySQL에 데이터 저장 작업 완료시 CouponIssueCreatedEvent 라는 도메인 이벤트 발급(publish)\nCouponIssueCreatedEvent 리스너는 @TransactionalEventListener 를 통해 트랜잭션 커밋이 완료된 couponId 를 Redis 내에 Cache Aside 기반의 캐싱 처리\n저장된 데이터의 모습\n{\"@class\":\"io.chagchagchag.project.coupon.dataaccess.cache.redis.valueobject.CouponRedisEntity\",\"id\":1,\"couponAssignType\":\"FIFO\",\"totalQuantity\":[\"java.math.BigDecimal\",1000],\"isQuantityAvailable\":false,\"issueStartDate\":[2024,1,1,0,0,1],\"issueEndDate\":[2024,11,11,23,59,59]}","추가-개발이-필요한-부분들#추가 개발이 필요한 부분들":"이번 프로젝트는 Redis Script 를 통해 단건 INSERT 트래픽 (쿠폰 발급)을 어떻게 부하를 줄여서 처리하는 지에 대한 예제를 남기는 것이 목적입니다. 제대로 한다면 예외 발생 시에 Kafka 토픽에 에러내용을 기록하거나 카프카 마저도 저장이 안될 경우 File 기반의 IO 작업을 수행하는 부분, 우아한 종료 로직 내에 장애 내용, 처리 시도 중인 ID 등을 기록하는 로직 등이 필요한데, 이런 내용은 주제에서 벗어나기에 생략했습니다.\n예외 케이스를 떠올리면서 이 정도로 변태 처럼 예외케이스를 생각할 필요는 없다구 하고 생각이 들어서 가급적 이번 예제는 트래픽을 단순하게 Redis 작업 큐 (LIST, SET) 기반으로 처리하는 예제를 남기는 데에 중점을 두었습니다."}},"/project-overview/tech-stack":{"title":"Tech Stack","data":{"library#Library":"Spring Boot 3.2.2\nGradle Kotlin DSL\nLanguage : Java 21\nSpring Data JPA, Querydsl\nGradle Jib","infra#Infra":"Docker, Docker Compose\nRedis\nMySQL"}},"/project-overview/prometheus-grafana-setting":{"title":"Prometheus Grafana Setting","data":{"prometheus-grafana-세팅#prometheus, grafana 세팅":"Prometheus 를 통해 애플리케이션이 모니터링 가능하도록 하고, Grafana 로 모니터링하는 과정을 설명합니다.\r\n이론적인 내용이나 개념도 설명할까 했는데, 피곤해서 거기까지는 설명을 못하고 어떻게 하는지만 설명을 남겨두기로 했습니다.","coupon-api#coupon-api":"","buildgradlekts#build.gradle.kts":"spring-boot-starter-actuator, micrometer-registry-prometheus 를 의존성으로 추가해줍니다.\n// ...\r\n\r\ndependencies {\r\n    // ...\r\n\r\n    // prometheus\r\n\timplementation(\"org.springframework.boot:spring-boot-starter-actuator\")\r\n\timplementation(\"io.micrometer:micrometer-registry-prometheus\")\r\n\r\n    // ...\r\n}","application-apiyml#application-api.yml":"application-api.yml 파일에 spring.application.name, server.tomcat.mbeanregistry.enabled, management.metrics.tags.application, management.endpoints.web.exposure.include = prometheus를 추가해줍니다.\nspring:\r\n  application:\r\n    name: coupon-api\r\n\r\n# ...\r\n# ...\r\n\r\nserver:\r\n  port: 8080\r\n  tomcat:\r\n    mbeanregistry:\r\n      enabled: true\r\nmanagement:\r\n  metrics:\r\n    tags:\r\n      application:\r\n        ${spring.application.name}\r\n  endpoints:\r\n    web:\r\n      exposure:\r\n        include: prometheus","coupon-issuer#coupon-issuer":"이번에는 coupon-issuer 측의 설정입니다.","buildgradlekts-1#build.gradle.kts":"spring-boot-starter-actuator, micrometer-registry-prometheus 를 의존성으로 추가해줍니다.\n// ...\r\n\r\ndependencies {\r\n    // ...\r\n\r\n    // prometheus\r\n\timplementation(\"org.springframework.boot:spring-boot-starter-actuator\")\r\n\timplementation(\"io.micrometer:micrometer-registry-prometheus\")\r\n\r\n    // ...\r\n}","application-issueryml#application-issuer.yml":"application-issuer.yml 파일에 spring.application.name, server.tomcat.mbeanregistry.enabled, management.metrics.tags.application, management.endpoints.web.exposure.include = prometheus를 추가해줍니다.\nspring:\r\n  application:\r\n    name: coupon-issuer\r\n\r\n# ...\r\n# ...\r\n\r\nserver:\r\n  port: 8081 # 8081 포트를 사용합니다. 주의해주세요.\r\n  tomcat:\r\n    mbeanregistry:\r\n      enabled: true\r\nmanagement:\r\n  metrics:\r\n    tags:\r\n      application:\r\n        ${spring.application.name}\r\n  endpoints:\r\n    web:\r\n      exposure:\r\n        include: prometheus","coupon-api-coupon-issuer-모듈-구동#coupon-api, coupon-issuer 모듈 구동":"coupon-api, coupon-issuer 모듈을 각각 스프링부트 애플리케이션으로 구동합니다. 각각 8080, 8081 포트에 구동됩니다.","prometheus-메트릭-조회-가능-여부-확인#prometheus 메트릭 조회 가능 여부 확인":"간단하게 coupon-api 측에서의 접근이 가능한지를 확인해봅니다.\r\nhttp://host.docker.internal:8080/actuator/prometheus 으로 접속해주세요. 만약 docker 에서 prometheus 를 띄우지 않고 로컬호스트에서 prometheus 를 구동했다면 http://localhost:8080/actuator/prometheus으로 접속하시면 됩니다.\n아래와 같이 메트릭 조회가 성공적으로 되어야 합니다. 비정상일 경우 White Label Error Page 오류가 나타납니다.\r\ncoupon-issuer 에 대해서도 같은 방식으로 동작을 확인해보시기 바랍니다.","docker-compose-prometheus-grafana-세팅#Docker-Compose Prometheus, Grafana 세팅":"","monitoringprometheusconfigconfigyml#monitoring/prometheus/config/config.yml":"0.performance-test/monitoring/prometheus/config/config.yml 을 아래와 같이 작성합니다.\nglobal:\r\n  scrape_interval: 5s\r\n\r\nscrape_configs:\r\n  - job_name: \"coupon-api\"\r\n    metrics_path: '/actuator/prometheus'\r\n    static_configs:\r\n      - targets: [ 'host.docker.internal:8080' ]\r\n  - job_name: \"coupon-issuer\"\r\n    metrics_path: '/actuator/prometheus'\r\n    static_configs:\r\n      - targets: [ 'host.docker.internal:8081' ]","docker-composeyml#docker-compose.yml":"0.performance-test/monitoring/docker-compose.yml 을 아래와 같이 작성합니다.\nversion: '3.7'\r\nservices:\r\n  prometheus:\r\n    image: prom/prometheus\r\n    container_name: prometheus\r\n    volumes:\r\n      - ./prometheus/config:/etc/prometheus\r\n      - ./prometheus/volume:/prometheus\r\n    ports:\r\n      - 9090:9090\r\n    command:\r\n      - '--config.file=/etc/prometheus/config.yml'\r\n    restart: always\r\n    networks:\r\n      - prometheus_network\r\n  grafana:\r\n    image: grafana/grafana\r\n    container_name: grafana\r\n    ports:\r\n      - 3000:3000\r\n    volumes:\r\n      - ./grafana/volume:/var/lib/grafana\r\n    restart: always\r\n    networks:\r\n      - prometheus_network\r\nnetworks:\r\n  prometheus_network:\r\n    driver: bridge\n작성이 완료되었으면 터미널에서 0.performance-test/monitoring/ 으로 이동 후에 아래의 명령어를 수행합니다.\ndocker-compose up -d","grafana-세팅#Grafana 세팅":"이번에는 Grafana 에서 Prometheus 를 설정하는 방식을 알아봅니다.","grafana-접속--패스워드-변경#Grafana 접속 & 패스워드 변경":"Grafana 에 접속합니다. 접속 주소는 http://localhost:3000 입니다.\r\nid = admin, password = admin 을 입력하고 접속합니다.\r\n비밀번호를 변경하는 페이지입니다. 비밀번호를 변경하기 귀찮다면 Skip 버튼을 클릭하고, 변경할 것이라면 New password, Confirm new password 를 모두 입력하고 Submit 버튼을 눌러서 비밀번호 변경을 완료합니다.","dashboard-생성-prometheus-세팅#Dashboard 생성, Prometheus 세팅":"새로 나타난 페이지에서는 Dashboard > Create your first dashboard 를 클릭해서 대시보드 설정 페이지로 이동합니다.\r\nImport a dashboard 를 클릭합니다.\r\n새로 나타난 페이지에서 4701 을 입력하고 Load 버튼을 클릭합니다.\r\nConfigure a new datasource 버튼을 클릭합니다.\r\n나타난 datasource 선택 화면에서 Prometheus 를 선택합니다.\r\nPrometheus URL 은 http://host.docker.internal:9090 을 입력해줍니다.\r\n스크롤을 아래로 내려서 Save & test 버튼을 클릭해서 Prometheus 설정을 마무리합니다.\r\n다시 홈으로 이동 후  Dashboard > Create your first dashboard 를 클릭해서 대시보드 설정 페이지로 이동합니다.\r\n그리고 Import a dashboard 를 클릭합니다.\r\nprometheus 를 선택하고 Import 버튼을 클릭합니다.\r\n설정이 완료되면 아래와 같은 화면이 나타납니다.","prometheus-대시보드#Prometheus 대시보드":"Prometheus 대시보드는 http://localhost:9090/ 으로 접속하시면 됩니다.\r\n그리고 상단의 Status 클릭 → Targets 클릭을 차례로 수행해주시면 됩니다.\r\n![](./img/PROMETHEUS-SCREENSHOT/1.그리고 상단의 Status 클릭 → Targets 클릭 png)\n아래에 나타나는 api 들은 모두 monitoring/prometheus/config/config.yml 에 미리 지정해준 내용을 기반으로 세팅된 내용들입니다","지표들을-지우고-싶다면#지표들을 지우고 싶다면":"prometheus, grafana 와 같은 시계열 데이터를 저장하는 플랫폼들은 대부분 측정한 지표들을 디스크내에 증분방식으로 쌓아둡니다. 우리가 작성한 docker-compose 파일 내에도 volume 항목을 보면 이런 내용들을 저장하는 부분들에 대한 내용이 있습니다.\r\n위에서 표시된 부분에 쌓인 데이터들을 지우려면 각각의 volume 디렉터리를 삭제해주시면 됩니다."}},"/redis-summary/redis-data-structures":{"title":"Redis Data Structures","data":{"레디스-자료구조들#레디스 자료구조들":""}},"/redis-summary/spring-data-redis":{"title":"Spring Data Redis","data":{"spring-data-redis#Spring Data Redis":""}}}